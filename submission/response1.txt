Authors' Responses
------------------

We gratefully thank the reviewer and the scientific editor for their time
and constructive comments that greatly helped improve this manuscript.
Based on the comments, we have improved the SKA image simulation with
another pair of image cubes, refined the training and interpretation of the
proposed convolutional denoising autoencoder (CDAE), added the comparison
to the continuous wavelet transform (CWT) method, and extensively revised
the manuscript with new sections and figures to describe our method and
results more thoroughly and clearly.

All the changes to the manuscript are highlighted in cyan.  The
point-by-point responses to the comments (indented with the ">" mark) are
listed below:


>   Scientific Editor's Comments
>   ----------------------------
>   I do not think this paper needs rapid publication as a Letter, but I
>   will be happy to consider a revised version for the main journal. You
>   should use the extra space this gives you to provide more details and
>   explanation, as suggested by the reviewer.
>
>   I think the paper would also be stronger if you could give more details
>   of the simulations, so that readers can judge what types of signals can
>   be distinguished from foregrounds by this method and which cannot.

Response 1:

In this revised manuscript, Section 3.1 ('Simulation of the SKA images')
has been rewritten to describe the whole simulation process in detail and
includes the following four major changes:

(1) We have added the description on the sky map simulation of the
foreground components, which includes the Galactic synchrotron and
free-free emissions, extragalactic point sources, and radio haloes.
Further simulation details can be found in Wang et al. (2010).

(2) More details about the SKA1-Low observation simulation from sky maps to
'observed' images have been provided.  Moreover, we have presented in
Figure 2 the simulated images of the foreground emission and the EoR signal
at 158 MHz as an example.

(3) We have simulated a second pair of image cubes (C2_eor, C2_fg) to be
used as the test set to evaluate the performance of the trained CDAE.  See
also Response 2 below.

(4) We have also clarified that no thermal noise was included in the
simulations.  See also Response 3 below.

>   It might be helpful to include images of the input EoR signal and the
>   recovered signal.

Response 2:

In the old manuscript, only one pair of image cubes were simulated and were
randomly partitioned into three sets (i.e., training, validation, and
test).  Therefore, it was impossible to obtain a complete image of the
reconstructed EoR signal.

In this revised version, we have simulated a second pair of image cubes
(C2_eor, C2_fg) as the test set and thus we can obtain the image cube of
the reconstructed EoR signal.  Based on this, the following two additional
results have been appended to Section 3.3 ('Training and results'):

(1) The 158 MHz images of the input and reconstructed EoR signals have been
illustrated in Figure 6;
(2) We have further calculated the two-dimensional power spectra of the
input and reconstructed EoR signals and presented the comparison in Figure 7.

Both results clearly show that the trained CDAE can accurately reconstruct
the EoR signal.

>   Did you include noise in your simulations?

Response 3:

Since the proposed method targets the tomographic EoR imaging, which would
be very deep pointed observations that could reach a sufficiently low noise
level of ~< 1 mK (e.g., Mellema et al. 2013), we do not include thermal
noise in the simulations.  This has been clarified in the last paragraph of
Section 3.1 ('Simulation of the SKA images').


>   Reviewer's Comments
>   -------------------
>   The paper presents an innovative methodology to extract relevant
>   information from noisy observations of 21 cm line emission from the
>   epoch of reionization, adopting a machine learning approach, based on a
>   Convolutional Denoising Autoencoder technique. The methodology, tested
>   on simulated data, proves to improve the performance of traditional
>   solutions.
>
>   The paper is properly written, although a more exhaustive description
>   of the methodology would be beneficial for the reader and the potential
>   user.  However, the page limit of the Letter does not allow extensive
>   add-ons.
>
>   Nevertheless, the main request of the reviewer is to describe in some
>   details how the Convolutional Neural Network (CNN) approach combines
>   with the Autoencoder methodology. As it is presented in the current
>   version of the paper, this is not clear and also Figure 1 is not
>   explicit enough to understand how the two methods work together. In
>   other words, it should be more explicitly stated that the "f(x)"
>   function of the encoder IS a combination of typical convolution+pooling
>   layers.

Response 4:

Compared to classic denoising autoencoders, which use fully connected
layers (e.g., Vincent et al. 2008,2010), a CDAE uses multiple convolutional
layers to gain the powerful feature extraction capability of convolutional
neural networks (CNNs) to improve its denoising performance (e.g., Du et al.
2017).  Both the encoder and decoder parts of the CDAE consist of multiple
convolutional layers, and each convolutional layer contains a number of
filters and an activation function.  The pooling and upsampling layers are
not used in the proposed CDAE architecture because they have very little
impact on the performance.

In this new manuscript, Sections 2.1 ('Convolutional denoising autoencoder')
and 2.2 ('Network architecture') have been greatly expanded to describe the
CDAE and the architecture design more clearly and completely.  We have also
updated Figure 1 to illustrate the proposed CDAE architecture more
intuitively.

>   If possible, it would also be beneficial to explain how the network
>   learns during the training (this second request only if space permits).

Response 5:

In order to gain some insights into how the CDAE learns, we have employed
the occlusion method to visualise the sensitivity distribution of the input
data, i.e., the performance loss induced by the occlusion of a small part
of the input data (Zeiler & Fergus 2014).  We find that the derived
sensitivity distribution is more correlated with the EoR signal than the
foreground emission (Figure 8), which verifies that the CDAE has actually
learned to distinguish the EoR signal from the foreground emission.

Moreover, we have tracked the variations of the sensitivity distribution
and its correlations with the EoR signal and the foreground emission along
the training process (Figure 9).  The tracking results suggest that the
CDAE first learns the major features of the EoR signal during the beginning
several (about 5) epochs and then it mainly learns the fine characteristic
of the EoR signal.

None the less, we note that a rigorously interpretation of the CDAE remains
a challenge and requires much more efforts.  A comprehensive understanding
of the CDAE is of great importance to further improve it and design more
efficient neural networks for practical EoR signal separation.  All these
contents have been added to the manuscript as the new Section 3.4 ('How the
CDAE learns?').

>   A further request is related to section 4.2 and the comparison with the
>   "polynomial fitting" method. It would be useful to specify if this is
>   the only alternative method for the kind of data processing presented
>   in the paper and, if not, to mention the others and to justify why they
>   have not been considered in the paper.

Response 6:

Multiple foreground removal methods have been proposed and can be broadly
classified into the parametric ones (e.g., Wang et al. 2006; Liu et al.
2009b; Wang et al. 2013) and the non-parametric ones (e.g., Harker et al.
2009; Gu et al. 2013; Chapman et al. 2013; Mertens et al. 2018).  Besides
the polynomial fitting method, which is the representative method in the
parametric method category, we have chosen the continuous wavelet transform
(CWT) method (Gu et al. 2013) among the non-parametric category in this new
manuscript for comparisons.  Moreover, the following two reasons were also
considered in choosing these two traditional methods:

(1) They both perform foreground removal along the frequency dimension
pixel-by-pixel, the same operation scheme as our method;
(2) They can give consistent and reliable results since they are intuitive
to implement and use.

Section 4.2 ('Comparing to traditional methods') has been rewritten to
mention more traditional foreground removal methods and to justify the
selection of the polynomial fitting method and the CWT method for comparing
with our method.

>   The only additional comment of the reviews regards the use of "EoR" in
>   the abstract. It would be clearer to avoid the acronym, explicitly
>   writing "epoch of reionization".

Response 7:

We now write the full name "epoch of reionization" when the "EoR" acronym
is first used in the abstract.
